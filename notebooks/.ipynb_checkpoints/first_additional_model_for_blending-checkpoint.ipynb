{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3a66656",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-11-12T14:03:19.731836Z",
     "iopub.status.busy": "2023-11-12T14:03:19.731493Z",
     "iopub.status.idle": "2023-11-12T14:03:48.367922Z",
     "shell.execute_reply": "2023-11-12T14:03:48.366820Z"
    },
    "papermill": {
     "duration": 28.643848,
     "end_time": "2023-11-12T14:03:48.370342",
     "exception": false,
     "start_time": "2023-11-12T14:03:19.726494",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightning\r\n",
      "  Obtaining dependency information for lightning from https://files.pythonhosted.org/packages/08/f0/617fede29ec0684b310bd2a0c880e640c60b9f2d64ed3d77e2bca2c13bf9/lightning-2.1.1-py3-none-any.whl.metadata\r\n",
      "  Downloading lightning-2.1.1-py3-none-any.whl.metadata (61 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.8/61.8 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: PyYAML<8.0,>=5.4 in /opt/conda/lib/python3.10/site-packages (from lightning) (6.0.1)\r\n",
      "Requirement already satisfied: fsspec[http]<2025.0,>2021.06.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (2023.10.0)\r\n",
      "Requirement already satisfied: lightning-utilities<2.0,>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (0.9.0)\r\n",
      "Requirement already satisfied: numpy<3.0,>=1.17.2 in /opt/conda/lib/python3.10/site-packages (from lightning) (1.24.3)\r\n",
      "Requirement already satisfied: packaging<25.0,>=20.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (21.3)\r\n",
      "Requirement already satisfied: torch<4.0,>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (2.0.0)\r\n",
      "Requirement already satisfied: torchmetrics<3.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (1.2.0)\r\n",
      "Requirement already satisfied: tqdm<6.0,>=4.57.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (4.66.1)\r\n",
      "Requirement already satisfied: typing-extensions<6.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (4.5.0)\r\n",
      "Requirement already satisfied: pytorch-lightning in /opt/conda/lib/python3.10/site-packages (from lightning) (2.1.0)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<2025.0,>2021.06.0->lightning) (2.31.0)\r\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<2025.0,>2021.06.0->lightning) (3.8.5)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging<25.0,>=20.0->lightning) (3.0.9)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch<4.0,>=1.12.0->lightning) (3.12.2)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch<4.0,>=1.12.0->lightning) (1.12)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch<4.0,>=1.12.0->lightning) (3.1)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch<4.0,>=1.12.0->lightning) (3.1.2)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning) (23.1.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning) (3.2.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning) (6.0.4)\r\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning) (4.0.3)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning) (1.9.2)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning) (1.4.0)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning) (1.3.1)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch<4.0,>=1.12.0->lightning) (2.1.3)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->fsspec[http]<2025.0,>2021.06.0->lightning) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->fsspec[http]<2025.0,>2021.06.0->lightning) (1.26.15)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->fsspec[http]<2025.0,>2021.06.0->lightning) (2023.7.22)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch<4.0,>=1.12.0->lightning) (1.3.0)\r\n",
      "Downloading lightning-2.1.1-py3-none-any.whl (2.0 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: lightning\r\n",
      "Successfully installed lightning-2.1.1\r\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.10/site-packages (3.9.0)\r\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.10/site-packages (from h5py) (1.24.3)\r\n"
     ]
    }
   ],
   "source": [
    "!pip3 install lightning\n",
    "!pip3 install h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5d3c753",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T14:03:48.381382Z",
     "iopub.status.busy": "2023-11-12T14:03:48.381061Z",
     "iopub.status.idle": "2023-11-12T14:03:56.042337Z",
     "shell.execute_reply": "2023-11-12T14:03:56.041374Z"
    },
    "papermill": {
     "duration": 7.669312,
     "end_time": "2023-11-12T14:03:56.044815",
     "exception": false,
     "start_time": "2023-11-12T14:03:48.375503",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import torch.utils.data as data\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import lightning.pytorch as L\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18879533",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T14:03:56.055819Z",
     "iopub.status.busy": "2023-11-12T14:03:56.055349Z",
     "iopub.status.idle": "2023-11-12T14:03:56.072162Z",
     "shell.execute_reply": "2023-11-12T14:03:56.071316Z"
    },
    "papermill": {
     "duration": 0.024306,
     "end_time": "2023-11-12T14:03:56.074050",
     "exception": false,
     "start_time": "2023-11-12T14:03:56.049744",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RadarDatasetNew(data.Dataset):\n",
    "\n",
    "    def __init__(self, list_of_files, in_seq_len=4, out_seq_len=12, mode='overlap', with_time=False):\n",
    "        self.in_seq_len = in_seq_len\n",
    "        self.out_seq_len = out_seq_len\n",
    "        self.seq_len = in_seq_len + out_seq_len\n",
    "        self.with_time = with_time\n",
    "        self.__prepare_timestamps_mapping(list_of_files)\n",
    "        self.__prepare_sequences(mode)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data = np.zeros((0,252,252))\n",
    "        inputs,targets = None,None\n",
    "        for n,timestamp in enumerate(self.sequences[index]):\n",
    "            if n < self.in_seq_len:\n",
    "                with h5py.File(self.timestamp_to_file[timestamp]) as d:\n",
    "                    new_data = np.array(d[timestamp]['intensity'])\n",
    "                data = np.vstack([data,np.expand_dims(new_data,axis=0)])\n",
    "            elif n == self.in_seq_len:\n",
    "                inputs = data.astype('float32')\n",
    "                with h5py.File(self.timestamp_to_file[timestamp]) as d:\n",
    "                    data = np.expand_dims(np.array(d[timestamp]['intensity']),axis=0)\n",
    "            else:\n",
    "                with h5py.File(self.timestamp_to_file[timestamp]) as d:\n",
    "                    new_data = np.array(d[timestamp]['intensity'])\n",
    "                data = np.vstack([data,np.expand_dims(new_data,axis=0)])\n",
    "        if inputs is None:\n",
    "            inputs = data.astype('float32')\n",
    "            targets = inputs[self.in_seq_len:]\n",
    "        else:\n",
    "            targets = data.astype('float32')\n",
    "        \n",
    "        if self.with_time:\n",
    "            return (inputs, self.sequences[index][-1]), targets\n",
    "        else:\n",
    "            return inputs, targets\n",
    "\n",
    "    def __prepare_timestamps_mapping(self, list_of_files):\n",
    "        self.timestamp_to_file = {}\n",
    "        for filename in list_of_files:\n",
    "            with h5py.File(filename) as d:\n",
    "                self.timestamp_to_file = {\n",
    "                    **self.timestamp_to_file,\n",
    "                    **dict(map(lambda x: (x, filename), d.keys()))\n",
    "                }\n",
    "\n",
    "    def __prepare_sequences(self, mode):\n",
    "        timestamps = np.unique(sorted(self.timestamp_to_file.keys()))\n",
    "        if mode == 'sequentially':\n",
    "            self.sequences = [\n",
    "                timestamps[index * self.seq_len: (index + 1) * self.seq_len]\n",
    "                for index in range(len(timestamps) // self.seq_len)\n",
    "            ]\n",
    "        elif mode == 'overlap':\n",
    "            self.sequences = [\n",
    "                timestamps[index: index + self.seq_len]\n",
    "                for index in range(len(timestamps) - self.seq_len + 1)\n",
    "            ]\n",
    "        else:\n",
    "            raise Exception(f'Unknown mode {mode}')\n",
    "        self.sequences = list(filter(\n",
    "            lambda x: int(x[-1]) - int(x[0]) == (self.seq_len - 1) * 600,\n",
    "            self.sequences\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a956cb8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T14:03:56.084159Z",
     "iopub.status.busy": "2023-11-12T14:03:56.083603Z",
     "iopub.status.idle": "2023-11-12T14:03:56.093543Z",
     "shell.execute_reply": "2023-11-12T14:03:56.092695Z"
    },
    "papermill": {
     "duration": 0.016941,
     "end_time": "2023-11-12T14:03:56.095438",
     "exception": false,
     "start_time": "2023-11-12T14:03:56.078497",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_data_loaders_new(train_batch_size=4, valid_batch_size=1, test_batch_size=1):\n",
    "    train_dataset = RadarDatasetNew([\n",
    "        '/kaggle/input/ycup2023-weather/prepared_train/2021-01-train.hdf5',\n",
    "        '/kaggle/input/ycup2023-weather/prepared_train/2021-02-train.hdf5',\n",
    "        '/kaggle/input/ycup2023-weather/prepared_train/2021-03-train.hdf5',\n",
    "        '/kaggle/input/ycup2023-weather/prepared_train/2021-04-train.hdf5',\n",
    "        '/kaggle/input/ycup2023-weather/prepared_train/2021-06-train.hdf5',\n",
    "        '/kaggle/input/ycup2023-weather/prepared_train/2021-07-train.hdf5', \n",
    "        '/kaggle/input/ycup2023-weather/prepared_train/2021-09-train.hdf5',\n",
    "        '/kaggle/input/ycup2023-weather/prepared_train/2021-10-train.hdf5',\n",
    "        '/kaggle/input/ycup2023-weather/prepared_train/2021-11-train.hdf5',\n",
    "        '/kaggle/input/ycup2023-weather/prepared_train/2021-12-train.hdf5',\n",
    "        '/kaggle/input/ycup2023-weather/prepared_train/2021-05-train.hdf5',\n",
    "        '/kaggle/input/ycup2023-weather/prepared_train/2021-08-train.hdf5',])\n",
    "    valid_dataset = RadarDatasetNew([\n",
    "        '/kaggle/input/ycup2023-weather/prepared_train/2021-05-train.hdf5',\n",
    "        '/kaggle/input/ycup2023-weather/prepared_train/2021-08-train.hdf5',\n",
    "    ])\n",
    "    test_dataset = RadarDatasetNew(['/kaggle/input/ycup2023-weather/prepared-test.hdf5'], out_seq_len=0, with_time=True)\n",
    "    train_loader = data.DataLoader(train_dataset, batch_size=train_batch_size, shuffle=True, num_workers=4)\n",
    "    valid_loader = data.DataLoader(valid_dataset, batch_size=valid_batch_size, shuffle=False)\n",
    "    test_loader = data.DataLoader(test_dataset, batch_size=test_batch_size, shuffle=False)\n",
    "    return train_loader, valid_loader, test_loader\n",
    "\n",
    "\n",
    "def process_test(model, test_loader, output_file='output.hdf5'):\n",
    "    model.eval()\n",
    "    with h5py.File(output_file, mode='w') as f_out:\n",
    "        for index, item in tqdm(enumerate(test_loader)):\n",
    "            (inputs, last_input_timestamp), _ = item\n",
    "            output = model(inputs)\n",
    "            for index in range(output.shape[1]):\n",
    "                timestamp_out = str(int(last_input_timestamp[-1]) + 600 * (index + 1))\n",
    "                f_out.create_group(timestamp_out)\n",
    "                f_out[timestamp_out].create_dataset(\n",
    "                    'intensity',\n",
    "                    data=output[0, index].cpu().detach().numpy()\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d90f9a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T14:03:56.105525Z",
     "iopub.status.busy": "2023-11-12T14:03:56.105273Z",
     "iopub.status.idle": "2023-11-12T14:03:56.139668Z",
     "shell.execute_reply": "2023-11-12T14:03:56.139011Z"
    },
    "papermill": {
     "duration": 0.041648,
     "end_time": "2023-11-12T14:03:56.141436",
     "exception": false,
     "start_time": "2023-11-12T14:03:56.099788",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RainNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv11 = nn.Conv2d(in_channels=4,out_channels=32, kernel_size=(3,3),padding=(1,1))\n",
    "        self.conv12 = nn.Conv2d(in_channels=32,out_channels=32, kernel_size=(3,3),padding=(1,1))\n",
    "        \n",
    "        self.conv21 = nn.Conv2d(in_channels=32,out_channels=64, kernel_size=(3,3),padding=(1,1))\n",
    "        self.conv22 = nn.Conv2d(in_channels=64,out_channels=64, kernel_size=(3,3),padding=(1,1))\n",
    "        \n",
    "        self.conv31 = nn.Conv2d(in_channels=64,out_channels=128, kernel_size=(3,3),padding=(1,1))\n",
    "        self.conv32 = nn.Conv2d(in_channels=128,out_channels=128, kernel_size=(3,3),padding=(1,1))\n",
    "        \n",
    "        self.conv41 = nn.Conv2d(in_channels=128,out_channels=256, kernel_size=(3,3),padding=(1,1))\n",
    "        self.conv42 = nn.Conv2d(in_channels=256,out_channels=256, kernel_size=(3,3),padding=(1,1))\n",
    "        self.drop4 = nn.Dropout(p=0.5)\n",
    "        \n",
    "        self.conv51 = nn.Conv2d(in_channels=256,out_channels=512, kernel_size=(3,3),padding=(1,1))\n",
    "        self.conv52 = nn.Conv2d(in_channels=512,out_channels=512, kernel_size=(3,3),padding=(1,1))\n",
    "        self.drop5 = nn.Dropout(p=0.5)\n",
    "        \n",
    "        self.up6 = nn.Upsample(size=(31,31))\n",
    "        self.drop6 = nn.Dropout(p=0.5)\n",
    "        self.conv61 = nn.Conv2d(in_channels=512+256,out_channels=256, kernel_size=(3,3),padding=(1,1))\n",
    "        self.conv62 = nn.Conv2d(in_channels=256,out_channels=256, kernel_size=(3,3),padding=(1,1))\n",
    "        \n",
    "        self.up7 = nn.Upsample(size=(63,63))\n",
    "        self.drop7 = nn.Dropout(p=0.5)\n",
    "        self.conv71 = nn.Conv2d(in_channels=256+128,out_channels=128, kernel_size=(3,3),padding=(1,1))\n",
    "        self.conv72 = nn.Conv2d(in_channels=128,out_channels=128, kernel_size=(3,3),padding=(1,1))\n",
    "        \n",
    "        self.up8 = nn.Upsample(size=(126,126))\n",
    "        self.drop8 = nn.Dropout(p=0.5)\n",
    "        self.conv81 = nn.Conv2d(in_channels=128+64,out_channels=64, kernel_size=(3,3),padding=(1,1))\n",
    "        self.conv82 = nn.Conv2d(in_channels=64,out_channels=64, kernel_size=(3,3),padding=(1,1))\n",
    "        \n",
    "        self.up9 = nn.Upsample(size=(252,252))\n",
    "        self.drop9 = nn.Dropout(p=0.5)\n",
    "        self.conv91 = nn.Conv2d(in_channels=64+32,out_channels=32, kernel_size=(3,3),padding=(1,1))\n",
    "        self.conv92 = nn.Conv2d(in_channels=32,out_channels=32, kernel_size=(3,3),padding=(1,1))\n",
    "        \n",
    "        self.conv10 = nn.Conv2d(in_channels=32,out_channels=12, kernel_size=(3,3),padding=(1,1))\n",
    "        \n",
    "        self.relu = torch.relu\n",
    "        self.max_pool = nn.MaxPool2d(2)\n",
    "\n",
    "    def forward(self, X):\n",
    "        num_batch, timestamps, height, width = X.size()\n",
    "        conv1f = self.conv11(X)\n",
    "        conv1f_relu = self.relu(conv1f)\n",
    "        conv1s = self.conv12(conv1f_relu)\n",
    "        conv1s_relu = self.relu(conv1s)\n",
    "        pool1 = self.max_pool(conv1s_relu)\n",
    "        \n",
    "        conv2f = self.conv21(pool1)\n",
    "        conv2f_relu = self.relu(conv2f)\n",
    "        conv2s = self.relu(self.conv22(conv2f_relu))\n",
    "        conv2s_relu = self.relu(conv2s)\n",
    "        pool2 = self.max_pool(conv2s_relu)\n",
    "        \n",
    "        conv3f = self.conv31(pool2)\n",
    "        conf3f_relu = self.relu(conv3f)\n",
    "        conv3s = self.conv32(conv3f)\n",
    "        conv3s_relu = self.relu(conv3s)\n",
    "        pool3 = self.max_pool(conv3s_relu)\n",
    "        \n",
    "        conv4f = self.conv41(pool3)\n",
    "        conv4f_relu = self.relu(conv4f)\n",
    "        conv4s = self.conv42(conv4f_relu)\n",
    "        conv4s_relu = self.relu(conv4s)\n",
    "        pool4 = self.drop4(self.max_pool(conv4s_relu))\n",
    "        \n",
    "        conv5f = self.conv51(pool4)\n",
    "        conv5f_relu = self.relu(conv5f)\n",
    "        conv5s = self.conv52(conv5f_relu)\n",
    "        conv5s_relu = self.relu(conv5s)\n",
    "        pool5 = self.drop5(conv5s_relu)\n",
    "        \n",
    "        up6 = self.up6(pool5)\n",
    "        up6_cnt = torch.concat([up6,conv4s_relu],axis=1)\n",
    "        conv6f = self.conv61(self.drop6(up6_cnt))\n",
    "        conv6f_relu = self.relu(conv6f)\n",
    "        conv6s = self.conv62(conv6f_relu)\n",
    "        conv6s_relu = self.relu(conv6s)\n",
    "        \n",
    "        up7 = self.up7(conv6s_relu)\n",
    "        up7_cnt = torch.concat([up7,conv3s_relu],axis=1)\n",
    "        conv7f = self.conv71(self.drop7(up7_cnt))\n",
    "        conv7f_relu = self.relu(conv7f)\n",
    "        conv7s = self.conv72(conv7f_relu)\n",
    "        conv7s_relu = self.relu(conv7s)\n",
    "        \n",
    "        up8 = self.up8(conv7s_relu)\n",
    "        up8_cnt = torch.concat([up8,conv2s_relu],axis=1)\n",
    "        conv8f = self.conv81(self.drop8(up8_cnt))\n",
    "        conv8f_relu = self.relu(conv8f)\n",
    "        conv8s = self.conv82(conv8f_relu)\n",
    "        conv8s_relu = self.relu(conv8s)\n",
    "        \n",
    "        up9 = self.up9(conv8s_relu)\n",
    "        up9_cnt = torch.concat([up9,conv1s_relu],axis=1)\n",
    "        conv9f = self.conv91(self.drop9(up9_cnt))\n",
    "        conv9f_relu = self.relu(conv9f)\n",
    "        conv9s = self.conv92(conv9f_relu)\n",
    "        conv9s_relu = self.relu(conv9s)\n",
    "        \n",
    "        conv10 = self.conv10(conv9s_relu)\n",
    "        \n",
    "        return conv10\n",
    "    \n",
    "    \n",
    "class RainNetModel(L.LightningModule):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = RainNet()\n",
    "        self.training_step_outputs = []\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.to(device=self.model.conv11.weight.device)\n",
    "        output = self.model(x)\n",
    "        return output\n",
    "\n",
    "    @staticmethod\n",
    "    def _augmentante(x):\n",
    "        return torch.cat([x,torch.rot90(x,dims=[2,3]),torch.rot90(x,dims=[2,3],k=2),torch.rot90(x,dims=[2,3],k=3)])\n",
    "\n",
    "    def training_step(self, batch):\n",
    "        x, y = batch\n",
    "        x,y = self._augmentante(x), self._augmentante(y)\n",
    "        out = self.forward(x)\n",
    "        loss = torch.mean(torch.sqrt(torch.sum(F.mse_loss(y,out,reduction='none')*(y > -0.999),axis=(0,2,3))/y.size()[0]))\n",
    "        self.training_step_outputs.append(loss)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "    \n",
    "    def on_train_epoch_end(self) -> None:\n",
    "        loss = torch.mean(torch.stack(self.training_step_outputs))\n",
    "        self.training_step_outputs.clear()\n",
    "        print('Train loss ',loss)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=5e-5)\n",
    "        lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.7)\n",
    "        return [optimizer],[lr_scheduler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7392c38d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T14:03:56.151378Z",
     "iopub.status.busy": "2023-11-12T14:03:56.151098Z",
     "iopub.status.idle": "2023-11-12T14:03:56.158293Z",
     "shell.execute_reply": "2023-11-12T14:03:56.157476Z"
    },
    "papermill": {
     "duration": 0.014334,
     "end_time": "2023-11-12T14:03:56.160239",
     "exception": false,
     "start_time": "2023-11-12T14:03:56.145905",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def main(tensorboard_path='/kaggle/working/tensorboard',max_epochs=3):\n",
    "    L.seed_everything(123321)\n",
    "    train_loader, valid_loader, test_loader = prepare_data_loaders_new()\n",
    "    model = RainNetModel()\n",
    "    checkpoint_callback = L.callbacks.ModelCheckpoint(every_n_epochs=1,save_on_train_epoch_end=True,save_top_k=-1)\n",
    "    lr_callback = L.callbacks.LearningRateMonitor(logging_interval='epoch')\n",
    "    trainer = L.Trainer(\n",
    "            logger=L.loggers.TensorBoardLogger(save_dir=tensorboard_path),\n",
    "            max_epochs=max_epochs,\n",
    "            deterministic=True,\n",
    "            callbacks=[checkpoint_callback, lr_callback]\n",
    "    )\n",
    "    trainer.fit(model, train_loader)\n",
    "    for epoch in range(max_epochs):\n",
    "        path = f\"{tensorboard_path}/lightning_logs/version_0/checkpoints\"\n",
    "        f_name = [_f for _f in os.listdir(path) if _f.find(f'epoch={epoch}') >= 0][0]\n",
    "        model = RainNetModel.load_from_checkpoint(path + '/' + f_name)\n",
    "        process_test(model, test_loader, output_file=f\"first_additional_model_for_blend_{epoch+1}_epoch_output.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d582a37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T14:03:56.170070Z",
     "iopub.status.busy": "2023-11-12T14:03:56.169785Z",
     "iopub.status.idle": "2023-11-12T16:03:32.354496Z",
     "shell.execute_reply": "2023-11-12T16:03:32.353379Z"
    },
    "papermill": {
     "duration": 7176.191728,
     "end_time": "2023-11-12T16:03:32.356488",
     "exception": false,
     "start_time": "2023-11-12T14:03:56.164760",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Seed set to 123321\n",
      "INFO: GPU available: True (cuda), used: True\n",
      "INFO: TPU available: False, using: 0 TPU cores\n",
      "INFO: IPU available: False, using: 0 IPUs\n",
      "INFO: HPU available: False, using: 0 HPUs\n",
      "WARNING: Missing logger folder: /kaggle/working/tensorboard/lightning_logs\n",
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO: \n",
      "  | Name  | Type    | Params\n",
      "----------------------------------\n",
      "0 | model | RainNet | 7.9 M \n",
      "----------------------------------\n",
      "7.9 M     Trainable params\n",
      "0         Non-trainable params\n",
      "7.9 M     Total params\n",
      "31.402    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d862d60770e94526b37667d1e65b248a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss  tensor(87.1774, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Train loss  tensor(84.9229, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: `Trainer.fit` stopped: `max_epochs=2` reached.\n",
      "96it [00:06, 14.07it/s]\n",
      "96it [00:06, 14.65it/s]\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 7219.329738,
   "end_time": "2023-11-12T16:03:35.695428",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-11-12T14:03:16.365690",
   "version": "2.4.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "03ddf132d6c7492aa31f64194a9b14b6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "418b9cbc25904577bd51338b1e673e37": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ef90e978c9dd4d34b3be2c22845612b0",
       "placeholder": "​",
       "style": "IPY_MODEL_82fcca5c38e2401d878499bd81135fd2",
       "value": " 12802/12802 [59:46&lt;00:00,  3.57it/s, v_num=0]"
      }
     },
     "461339ba1fb54a5facbd81136ce1780f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": "2",
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "82fcca5c38e2401d878499bd81135fd2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "85ea3c6a05464f24be770d8e429197af": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8fd02600d66a45ff9a31c94514a9b00c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": "inline-flex",
       "flex": null,
       "flex_flow": "row wrap",
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "100%"
      }
     },
     "9a5a508f84864607804fad026f257499": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_85ea3c6a05464f24be770d8e429197af",
       "placeholder": "​",
       "style": "IPY_MODEL_a61728be91854e3599f5445176684811",
       "value": "Epoch 1: 100%"
      }
     },
     "a61728be91854e3599f5445176684811": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "aeb7e79152a4427691cbe1f1a00aa8b1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_461339ba1fb54a5facbd81136ce1780f",
       "max": 12802,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_03ddf132d6c7492aa31f64194a9b14b6",
       "value": 12802
      }
     },
     "d862d60770e94526b37667d1e65b248a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_9a5a508f84864607804fad026f257499",
        "IPY_MODEL_aeb7e79152a4427691cbe1f1a00aa8b1",
        "IPY_MODEL_418b9cbc25904577bd51338b1e673e37"
       ],
       "layout": "IPY_MODEL_8fd02600d66a45ff9a31c94514a9b00c"
      }
     },
     "ef90e978c9dd4d34b3be2c22845612b0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
